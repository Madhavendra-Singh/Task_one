# -*- coding: utf-8 -*-
"""Task1_Intern.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sQMev01J6yqUEispF0E9ResVniRbJ6aj
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the Titanic dataset
df = pd.read_csv("task1_Titanic-Dataset.csv")

# Show basic structure and column data types
df.info()
df.describe(include='all')
df.head()

# Drop columns that are not useful for prediction or have too many missing/unique values
df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)

# Identify numerical columns (excluding the target variable 'Survived')
numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
numerical_cols.remove('Survived')
print("Numerical Columns:", numerical_cols)

# Plot histograms for each numerical column to understand distributions
for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    plt.hist(df[col], bins=30, color='skyblue', edgecolor='black')
    plt.title(f"Histogram of {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()

# Plot boxplots to detect outliers in numerical columns (before handling)
for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot BEFORE Outlier Handling: {col}")
    plt.show()

# Apply IQR method to cap outliers in each numerical column
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    df[col] = np.where(df[col] < lower, lower, df[col])
    df[col] = np.where(df[col] > upper, upper, df[col])

# Plot boxplots again to verify that outliers have been capped
for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot AFTER Outlier Handling: {col}")
    plt.show()

# Identify categorical columns
categorical_columns = df.select_dtypes(include=["object"]).columns.tolist()
print("Categorical Columns:", categorical_columns)

# Plot pie charts to visualize the distribution of categories
for col in categorical_columns:
    plt.figure(figsize=(6, 6))
    df[col].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)
    plt.title(f"Pie Chart: {col}")
    plt.ylabel('')
    plt.show()

# Display number of missing values before handling
print(df.isnull().sum())

# Fill missing values in numerical columns with the median
for col in numerical_cols:
    if df[col].isnull().sum() > 0:
        df[col] = df[col].fillna(df[col].median())

# Fill missing values in categorical columns with the most frequent value (mode)
for col in categorical_columns:
    if df[col].isnull().sum() > 0:
        df[col] = df[col].fillna(df[col].mode()[0])

# Check again to ensure no missing values remain
print(df.isnull().sum())

# Create a correlation heatmap for numerical features
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap of Titanic Dataset')
plt.show()

# Print the covariance matrix of numeric columns
cov_matrix = df.cov(numeric_only=True)
print("Covariance Matrix:\n", cov_matrix)

# Encode categorical variables using Label Encoding
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

# Standardize the numerical features using StandardScaler
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

# Show that data is now standardized (mean ~0, std ~1)
df[numerical_cols].describe()

# Export the cleaned dataset to a new CSV file
df.to_csv("cleaned_titanic.csv", index=False)